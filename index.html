<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LinearCosine: Benchmarking L-Mul Algorithm</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f0f7f0;
            color: #333;
            line-height: 1.6;
            margin: 0;
            padding: 0;
        }
        .container {
            width: 90%;
            margin: auto;
            overflow: hidden;
            padding: 20px;
        }
        header {
            background: #2e8b57;
            color: #ffffff;
            padding: 20px 0;
            min-height: 70px;
            border-bottom: 3px solid #3cb371;
            border-radius: 0 0 20px 20px;
        }
        header h1 {
            margin: 0;
            text-align: center;
        }
        .button {
            display: inline-block;
            background: #3cb371;
            padding: 10px 20px;
            color: #ffffff;
            text-decoration: none;
            border-radius: 5px;
            transition: background-color 0.3s;
        }
        .button:hover {
            background: #4caf50;
        }
        .disclaimer {
            background-color: #e8f5e9;
            border: 2px solid #2e8b57;
            padding: 15px;
            margin: 20px 0;
            border-radius: 10px;
            font-style: italic;
        }
        h2 {
            color: #2e8b57;
            border-bottom: 2px solid #2e8b57;
            padding-bottom: 10px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
            font-size: 0.9em;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #2e8b57;
            color: white;
        }
        tr:nth-child(even) {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>LinearCosine: Benchmarking L-Mul Algorithm</h1>
        </div>
    </header>

    <div class="container">
        <div class="disclaimer">
            <strong>Important Note:</strong> This project is an unofficial benchmark implementation focusing on cosine similarity calculations, based on concepts from the research paper "Addition is All You Need for Energy-efficient Language Models" by Hongyin Luo and Wei Sun (2024). It applies their proposed L-Mul algorithm to cosine similarity computations, but is not the original work of the authors and is intended solely for my own exploratory purposes.
        </div>

        <p style="text-align: center;">
            <a href="https://github.com/AmanPriyanshu/LinearCosine" class="button" target="_blank">GitHub Implementation of Below</a>
            <a href="https://arxiv.org/abs/2410.00907" class="button" target="_blank">Read the Original Paper</a>
        </p>

        <h2>TLDR: Technical Explanation</h2>
        <p>The L-Mul algorithm proposes an efficient approximation of floating-point multiplication using primarily integer addition operations. Here's a quick breakdown:</p>

        <h3>Standard Floating-Point Multiplication</h3>
        <p>The traditional method multiplies two floating-point numbers as follows:</p>
        <pre><code>Mul(x,y) = (1 + x_m) · 2^x_e · (1 + y_m) · 2^y_e
                = (1 + x_m + y_m + x_m · y_m) · 2^(x_e + y_e)</code></pre>
        <p>Where x_m and y_m are mantissas, and x_e and y_e are exponents.</p>

        <h3>L-Mul Algorithm</h3>
        <p>The L-Mul method approximates this multiplication:</p>
        <pre><code>L-Mul(x,y) = (1 + x_m + y_m + 2^-l(m)) · 2^(x_e + y_e)</code></pre>
        <p>Where l(m) is defined as:</p>
        <pre><code>l(m) = {
            m   if m ≤ 3,
            3   if m = 4,
            4   if m > 4
        }</code></pre>
        <p>Here, m represents the number of mantissa bits.</p>

        <h3>Key Differences</h3>
        <ul>
            <li>L-Mul replaces the x_m · y_m term with a constant 2^-l(m).</li>
            <li>This substitution allows the operation to be performed primarily with integer addition.</li>
            <li>The l(m) function adjusts the precision based on the number of mantissa bits used.</li>
        </ul>

        <p>The paper states that this approximation significantly reduces computational complexity and energy consumption while maintaining competitive accuracy, especially for lower-precision operations common in many AI tasks.</p>

        <h2>About This Benchmark</h2>
        <p>
            This benchmark explores the Linear-complexity Multiplication (L-Mul) algorithm proposed by Luo and Sun in their 2024 paper. Our goal is to provide a practical implementation of their concepts, focusing on cosine similarity calculations. This project is not affiliated with or endorsed by the original authors.
        </p>

        <h2>Experiment Overview</h2>
        <p>
            We've implemented the L-Mul algorithm as described by Luo and Sun, comparing its performance against standard multiplication in cosine similarity computations. Our benchmarks cover:
        </p>
        <ul>
            <li>1D to 1D vector cosine similarity</li>
            <li>1D to 2D vector cosine similarity</li>
            <li>2D to 2D matrix cosine similarity</li>
        </ul>

        <h2>Results</h2>

        <h3>1D to 1D Cosine Similarity</h3>
        <table>
            <tr>
                <th>Mantissa Bits</th>
                <th>L-Mul MSE</th>
                <th>L-Mul Time (ns)</th>
                <th>Mul MSE</th>
                <th>Mul Time (ns)</th>
                <th>Time Reduction (%)</th>
            </tr>
            <tr><td>2</td><td>9.45862e-06</td><td>507</td><td>4.07024e-08</td><td>670</td><td>24.3284%</td></tr>
            <tr><td>3</td><td>1.84347e-05</td><td>459</td><td>4.07024e-08</td><td>597</td><td>23.1156%</td></tr>
            <tr><td>4</td><td>1.84347e-05</td><td>383</td><td>4.07024e-08</td><td>516</td><td>25.7752%</td></tr>
            <tr><td>5</td><td>4.44707e-05</td><td>477</td><td>1.93169e-06</td><td>629</td><td>24.1653%</td></tr>
            <tr><td>6</td><td>1.78036e-05</td><td>477</td><td>6.42665e-08</td><td>625</td><td>23.68%</td></tr>
            <tr><td>7</td><td>2.11236e-05</td><td>498</td><td>2.21875e-08</td><td>654</td><td>23.8532%</td></tr>
            <tr><td>8</td><td>2.0259e-05</td><td>442</td><td>1.28071e-09</td><td>589</td><td>24.9576%</td></tr>
            <tr><td>9</td><td>1.9652e-05</td><td>460</td><td>6.87609e-09</td><td>607</td><td>24.2175%</td></tr>
            <tr><td>10</td><td>1.84467e-05</td><td>444</td><td>7.4093e-10</td><td>588</td><td>24.4898%</td></tr>
            <tr><td>11</td><td>1.82827e-05</td><td>506</td><td>6.00017e-10</td><td>669</td><td>24.3647%</td></tr>
            <tr><td>12</td><td>1.80075e-05</td><td>433</td><td>1.11101e-10</td><td>572</td><td>24.3007%</td></tr>
            <tr><td>13</td><td>1.79965e-05</td><td>487</td><td>1.01831e-10</td><td>643</td><td>24.2613%</td></tr>
            <tr><td>14</td><td>1.79698e-05</td><td>494</td><td>2.53293e-11</td><td>657</td><td>24.8097%</td></tr>
            <tr><td>15</td><td>1.79675e-05</td><td>460</td><td>1.13981e-12</td><td>609</td><td>24.4663%</td></tr>
            <tr><td>16</td><td>1.79675e-05</td><td>386</td><td>1.02339e-12</td><td>520</td><td>25.7692%</td></tr>
            <tr><td>17</td><td>1.79673e-05</td><td>435</td><td>3.19744e-14</td><td>580</td><td>25.0%</td></tr>
            <tr><td>18</td><td>1.79673e-05</td><td>396</td><td>3.19744e-14</td><td>532</td><td>25.5639%</td></tr>
            <tr><td>19</td><td>1.79673e-05</td><td>402</td><td>1.42109e-14</td><td>539</td><td>25.4174%</td></tr>
            <tr><td>20</td><td>1.79673e-05</td><td>496</td><td>0</td><td>651</td><td>23.8095%</td></tr>
            <tr><td>21</td><td>1.79673e-05</td><td>477</td><td>0</td><td>627</td><td>23.9234%</td></tr>
            <tr><td>22</td><td>1.79673e-05</td><td>431</td><td>0</td><td>572</td><td>24.6503%</td></tr>
            <tr><td>23</td><td>1.79673e-05</td><td>415</td><td>0</td><td>555</td><td>25.2252%</td></tr>
        </table>

        <h4>Summary</h4>
        <ul>
            <li><strong>Average Time Reduction:</strong> 24.55%</li>
            <li><strong>Average L-Mul MSE:</strong> 1.9184e-05</li>
        </ul>

        <h3>1D to 2D Cosine Similarity</h3>
        <table>
            <tr>
                <th>Mantissa Bits</th>
                <th>L-Mul MSE</th>
                <th>L-Mul Time (ns)</th>
                <th>Mul MSE</th>
                <th>Mul Time (ns)</th>
                <th>Time Reduction (%)</th>
            </tr>
            <tr><td>2</td><td>4.67427e-05</td><td>1676</td><td>4.55376e-07</td><td>2017</td><td>16.9063%</td></tr>
            <tr><td>3</td><td>7.48827e-05</td><td>1677</td><td>4.55376e-07</td><td>2016</td><td>16.8155%</td></tr>
            <tr><td>4</td><td>7.48827e-05</td><td>1710</td><td>4.55376e-07</td><td>2091</td><td>18.2209%</td></tr>
            <tr><td>5</td><td>9.02946e-05</td><td>1773</td><td>6.61553e-07</td><td>2165</td><td>18.1062%</td></tr>
            <tr><td>6</td><td>7.6781e-05</td><td>1794</td><td>8.51294e-08</td><td>2200</td><td>18.4545%</td></tr>
            <tr><td>7</td><td>7.59022e-05</td><td>1748</td><td>2.00377e-08</td><td>2134</td><td>18.0881%</td></tr>
            <tr><td>8</td><td>7.49402e-05</td><td>1760</td><td>2.28993e-09</td><td>2148</td><td>18.0633%</td></tr>
            <tr><td>9</td><td>7.32966e-05</td><td>1730</td><td>2.9637e-09</td><td>2116</td><td>18.242%</td></tr>
            <tr><td>10</td><td>7.24353e-05</td><td>1775</td><td>5.58836e-10</td><td>2162</td><td>17.9001%</td></tr>
            <tr><td>11</td><td>7.19966e-05</td><td>1721</td><td>2.21817e-10</td><td>2093</td><td>17.7735%</td></tr>
            <tr><td>12</td><td>7.17846e-05</td><td>1739</td><td>4.44593e-11</td><td>2122</td><td>18.049%</td></tr>
            <tr><td>13</td><td>7.14999e-05</td><td>1641</td><td>3.42347e-11</td><td>2008</td><td>18.2769%</td></tr>
            <tr><td>14</td><td>7.1498e-05</td><td>1708</td><td>8.72289e-12</td><td>2083</td><td>18.0029%</td></tr>
            <tr><td>15</td><td>7.15258e-05</td><td>1610</td><td>3.84912e-13</td><td>1972</td><td>18.357%</td></tr>
            <tr><td>16</td><td>7.15262e-05</td><td>1661</td><td>3.46476e-13</td><td>2035</td><td>18.3784%</td></tr>
            <tr><td>17</td><td>7.15261e-05</td><td>1663</td><td>1.53951e-14</td><td>2034</td><td>18.2399%</td></tr>
            <tr><td>18</td><td>7.15261e-05</td><td>1646</td><td>1.53951e-14</td><td>2013</td><td>18.2315%</td></tr>
            <tr><td>19</td><td>7.15261e-05</td><td>1598</td><td>4.73695e-15</td><td>1963</td><td>18.594%</td></tr>
            <tr><td>20</td><td>7.15256e-05</td><td>1727</td><td>1.18424e-15</td><td>2110</td><td>18.1517%</td></tr>
            <tr><td>21</td><td>7.15261e-05</td><td>1634</td><td>5.92119e-15</td><td>1997</td><td>18.1773%</td></tr>
            <tr><td>22</td><td>7.15256e-05</td><td>1653</td><td>4.73695e-15</td><td>2023</td><td>18.2897%</td></tr>
            <tr><td>23</td><td>7.15256e-05</td><td>1693</td><td>0</td><td>2068</td><td>18.1335%</td></tr>
        </table>

        <h3>2D to 2D Cosine Similarity</h3>
        <table>
            <tr>
                <th>Mantissa Bits</th>
                <th>L-Mul Time (ns)</th>
                <th>Mul MSE</th>
                <th>Mul Time (ns)</th>
                <th>Time Reduction (%)</th>
            </tr>
            <tr><td>2</td><td>2.95e-04</td><td>6048</td><td>2.00e-06</td><td>7742</td><td>21.88%</td></tr>
            <tr><td>3</td><td>4.25e-04</td><td>6022</td><td>2.00e-06</td><td>7723</td><td>22.03%</td></tr>
            <tr><td>4</td><td>4.48e-04</td><td>6138</td><td>2.00e-06</td><td>7931</td><td>22.61%</td></tr>
            <tr><td>5</td><td>5.03e-04</td><td>6140</td><td>1.00e-06</td><td>7934</td><td>22.61%</td></tr>
            <tr><td>6</td><td>4.74e-04</td><td>6341</td><td>0.00e+00</td><td>8162</td><td>22.31%</td></tr>
            <tr><td>7</td><td>4.80e-04</td><td>6194</td><td>0.00e+00</td><td>8003</td><td>22.60%</td></tr>
            <tr><td>8</td><td>4.81e-04</td><td>5761</td><td>0.00e+00</td><td>7482</td><td>23.00%</td></tr>
            <tr><td>9</td><td>4.77e-04</td><td>5752</td><td>0.00e+00</td><td>7447</td><td>22.76%</td></tr>
            <tr><td>10</td><td>4.74e-04</td><td>6243</td><td>0.00e+00</td><td>8059</td><td>22.53%</td></tr>
            <tr><td>11</td><td>4.74e-04</td><td>6241</td><td>0.00e+00</td><td>8075</td><td>22.71%</td></tr>
            <tr><td>12</td><td>4.74e-04</td><td>5728</td><td>0.00e+00</td><td>7447</td><td>23.08%</td></tr>
            <tr><td>13</td><td>4.74e-04</td><td>5950</td><td>0.00e+00</td><td>7720</td><td>22.93%</td></tr>
            <tr><td>14</td><td>4.74e-04</td><td>6217</td><td>0.00e+00</td><td>8029</td><td>22.57%</td></tr>
            <tr><td>15</td><td>4.74e-04</td><td>5809</td><td>0.00e+00</td><td>7541</td><td>22.97%</td></tr>
            <tr><td>16</td><td>4.74e-04</td><td>6322</td><td>0.00e+00</td><td>8163</td><td>22.55%</td></tr>
            <tr><td>17</td><td>4.74e-04</td><td>5939</td><td>0.00e+00</td><td>7681</td><td>22.68%</td></tr>
            <tr><td>18</td><td>4.74e-04</td><td>5900</td><td>0.00e+00</td><td>7649</td><td>22.87%</td></tr>
            <tr><td>19</td><td>4.74e-04</td><td>5774</td><td>0.00e+00</td><td>7491</td><td>22.92%</td></tr>
            <tr><td>20</td><td>4.74e-04</td><td>5687</td><td>0.00e+00</td><td>7397</td><td>23.12%</td></tr>
            <tr><td>21</td><td>4.74e-04</td><td>5875</td><td>0.00e+00</td><td>7628</td><td>22.98%</td></tr>
            <tr><td>22</td><td>4.74e-04</td><td>6026</td><td>0.00e+00</td><td>7815</td><td>22.89%</td></tr>
            <tr><td>23</td><td>4.74e-04</td><td>5916</td><td>0.00e+00</td><td>7645</td><td>22.62%</td></tr>
        </table>

        <h2>Key Findings</h2>
        <ul>
            <li>The L-Mul approach consistently achieves time reductions across all scenarios.</li>
            <li>For 1D to 1D cosine similarity, the average time reduction is 24.55%.</li>
            <li>In 1D to 2D scenarios, time reductions range from about 16.8% to 18.6%.</li>
            <li>For 2D to 2D calculations, time reductions are between 21.88% and 23.12%.</li>
            <li>The L-Mul method maintains acceptable levels of accuracy (measured by MSE) for most practical applications.</li>
        </ul>

        <h2>Limitations</h2>
        <ul>
            <li>This is a simplified implementation and may not capture all nuances of the original proposal by Luo and Sun.</li>
            <li>Our benchmarks focus on raw computation time, which may not directly translate to energy efficiency.</li>
            <li>Results may vary significantly in real-world applications or different hardware environments.</li>
            <li>The time efficiency gains observed here don't necessarily equate to compute or energy efficiency in real-world scenarios.</li>
        </ul>

        <h2>Conclusion</h2>
        <p>
            Our benchmark results suggest that the L-Mul algorithm, as proposed by Luo and Sun, shows promise in reducing computation time for cosine similarity calculations across various dimensions. However, it's important to note that these results are based on a simplified C++ implementation and may not fully reflect the algorithm's performance in more complex, real-world scenarios or on specialized hardware.
        </p>

        <h2>Acknowledgments</h2>
        <p>
            All credit for the L-Mul algorithm and its theoretical foundations goes to Hongyin Luo and Wei Sun, as presented in their 2024 paper. This benchmark is an independent exploration of their concepts and should not be considered an official implementation or extension of their work.
        </p>

        <h2>Citation</h2>
        <pre>
@misc{luo2024additionneedenergyefficientlanguage,
    title={Addition is All You Need for Energy-efficient Language Models}, 
    author={Hongyin Luo and Wei Sun},
    year={2024},
    eprint={2410.00907},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2410.00907}, 
}
        </pre>

        <h2>Disclaimer</h2>
        <p>
            This project is for educational purposes only. It is not intended for production use and does not claim to accurately represent the full potential or limitations of the L-Mul algorithm as proposed by Luo and Sun. Users are encouraged to refer to the original paper for authoritative information.
        </p>
    </div>
</body>
</html>